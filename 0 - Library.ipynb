{"cells":[{"cell_type":"code","source":["# Copyright 2021 D-Wave Systems Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#        http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nimport numpy as np\nimport networkx as nx\n\ndef plot_bqm(bqm):\n    \"\"\"Plot binary quadratic model as a labeled graph.\"\"\"\n    g = nx.Graph()\n    g.add_nodes_from(bqm.variables)\n    g.add_edges_from(bqm.quadratic)\n\n    plt.figure(figsize=(8, 8))\n    ax = plt.gca()\n    ax.set_title(f\"BQM with {len(bqm)} nodes and {len(bqm.quadratic)} edges\")\n    nx.draw_circular(g, with_labels=True, node_size=3000, node_color=\"y\")\n    plt.show()\n\ndef plot_feature_selection(features, selected_features):\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_axes([0.1, 0.3, .9, .7])\n    ax.set_title(\"Best Feature Selection\")\n    ax.set_ylabel('Number of Selected Features')\n    ax.set_xticks(np.arange(len(features)))\n    ax.set_xticklabels(features, rotation=90)\n    ax.set_yticks(np.arange(len(features)))\n    ax.set_yticklabels(np.arange(1, len(features)+1))\n    # Set a grid on minor ticks\n    ax.set_xticks(np.arange(-0.5, len(features)), minor=True)\n    ax.set_yticks(np.arange(-0.5, len(features)), minor=True)\n    ax.grid(which='minor', color='black')\n    ax.imshow(selected_features, cmap=colors.ListedColormap(['white', 'red']))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a565aca2-c187-4580-a6b4-b140ea982788"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Copyright 2021 D-Wave Systems Inc.\n#\n#    Licensed under the Apache License, Version 2.0 (the \"License\");\n#    you may not use this file except in compliance with the License.\n#    You may obtain a copy of the License at\n#\n#        http://www.apache.org/licenses/LICENSE-2.0\n#\n#    Unless required by applicable law or agreed to in writing, software\n#    distributed under the License is distributed on an \"AS IS\" BASIS,\n#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#    See the License for the specific language governing permissions and\n#    limitations under the License.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.colors as colors\n\ndef two_var_model(in_tuple, a, b):\n    ina, inb = in_tuple\n    return a*ina + b*inb\n\ndef sub_plot(size, small, big, x, subtitles, y, *y2):\n    gs = GridSpec(big + 1, small)\n    plt.figure(figsize=size)\n    for i in range(small):\n        ax = 'ax_' + str(i)\n        ax = plt.subplot(gs[0, i])\n        ax.set_title(subtitles[i])\n        if y2:\n            ax.plot(x, y2[0]['out'].values, 'ro')\n            ax.plot(x, y[y.columns[i]].values, 'bv')\n            ax.legend([\"out\", \"model\"])\n        else:\n            ax.plot(x, y[y.columns[i]].values)\n\n    if big:\n        axy = plt.subplot(gs[1, :])\n        i += 1\n        axy.set_title(y.columns[i])\n        axy.plot(x, y[y.columns[i]].values, 'r')\n    return plt\n\ndef plot_toy_signals(df):\n    sub_plot((10, 8), 3, True, np.linspace(-np.pi, np.pi, len(df)), df.columns, df)\n    plt.suptitle(\"Toy Problem: System Inputs and Output\", fontsize=15)\n\ndef plot_two_var_model(df1, df2):\n    subtitles = [\"Modeling %s and %s\" % f0f1 for f0f1 in df1.columns]\n    sub_plot((12, 4), 3, 0, np.linspace(-np.pi, np.pi, len(df1)), subtitles, df1, df2)\n    plt.suptitle(\"Toy Problem: Output Vesus Two-Signal Model\", fontsize=15)\n\ndef plot_lingress(df, toy):\n    subtitles = [\"%s correlation coefficient: %.2f\" % var_rval for var_rval in df.columns]\n    sub_plot((12, 4), 3, 0, np.linspace(-np.pi, np.pi, len(df)), subtitles, df, toy)\n    plt.suptitle(\"Toy Problem: Linear Regression\", fontsize=15)\n\n# Warning since 0.24.2\n#def plot_se(data):\n#    pd.DataFrame(data).plot(x='Bins', y=['Maximum', 'Uniform', 'Exp', 'Vals'], style = [ 'ro','b', 'g', 'y'])\n#    plt.title(\"Shannon Entropy\")\n#    plt.ylabel(\"Entropy\")\ndef plot_se(data):\n    df = pd.DataFrame(data)\n    plt.figure(figsize=(5, 4))\n    plt.plot(df[['Bins']].values, df[['Maximum']].values, 'ro',\n             df[['Bins']].values, df[['Uniform']].values, 'b',\n             df[['Bins']].values, df[['Exp']].values, 'g',\n             df[['Bins']].values, df[['Vals']].values, 'y')\n    plt.title(\"Shannon Entropy\")\n    plt.xlabel(\"Bins\")\n    plt.ylabel(\"Entropy\")\n    plt.legend(['Maximum', 'Uniform', 'Exp', 'Vals'])\n\ndef plot_mi(scores):\n    if len(scores) > 5:\n        plt.figure(figsize=(8, 5))\n    else:\n        plt.figure(figsize=(4, 4))\n    labels, values = zip(*sorted(scores.items(), key=lambda pair: pair[1], reverse=True))\n    plt.bar(np.arange(len(labels)), values)\n    plt.xticks(np.arange(len(labels)), labels, rotation=90)\n    plt.bar(np.arange(len(labels)), values)\n    plt.xticks(np.arange(len(labels)), labels, rotation=90)\n    plt.title(\"Mutual Information\")\n    plt.ylabel(\"MI with Variable of Interest\")\n\ndef plot_solutions(result):\n    features = []\n    energies = []\n    for sample, energy in result.data(['sample', 'energy']):\n        energies.append(energy)\n        features.append([key for (key, value) in sample.items() if value == 1])\n    plt.figure(figsize=(40, 20))\n    plt.bar(np.arange(len(features)), energies)\n    plt.xticks(np.arange(len(features)), features, rotation=90)\n    #plt.title(\"Toy Problem: Unconstrained Solution\")\n    plt.ylabel(\"Energy\")\n\ndef plot_features(features, selected_features):\n    fig = plt.figure(figsize=(6, 6))\n    ax = fig.add_axes([0.1, 0.3, .9, .7])\n    ax.set_title(\"Best Feature Selection\")\n    ax.set_ylabel('Number of Selected Features')\n    ax.set_xticks(np.arange(len(features)))\n    ax.set_xticklabels(features, rotation=90)\n    ax.set_yticks(np.arange(len(features)))\n    ax.set_yticklabels(np.arange(1, len(features)+1))\n    # Set a grid on minor ticks\n    ax.set_xticks(np.arange(-0.5, len(features)), minor=True)\n    ax.set_yticks(np.arange(-0.5, len(features)), minor=True)\n    ax.grid(which='minor', color='black')\n    ax.imshow(selected_features, cmap=colors.ListedColormap(['white', 'red']))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74c77489-2097-4ab9-b3b7-46fc78ac07d5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Quantifying Information: Shannon Entropy\n[Shannon entropy](https://en.wiktionary.org/wiki/Shannon_entropy), $H(X)$,  mathematically quantifies the information in a signal:\n\n$H(X) = - \\sum_{x \\in X} p(x) \\log p(x)$\n\nwhere $p(x)$ represents the probability of an event's occurrence. The Shannon Entropy (SE) formula can be understood as weighing by an event's probability a value of $\\log \\frac{1}{p(x)}$ for the event, where the reciprocal is due to the minus sign. This value means that the less likely the occurrence of an event, the more information is attributed to it (intuitively, when a man bites a dog it's news). \n\nTo calculate SE, the `prob` function defined below calculates probability for a dataset representing some variables (a training set in a machine learning context) by dividing it into bins as a histogram using the NumPy library's `histogramdd` function."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c471b80c-1ae4-470d-9ae3-aec8de44fa7d"}}},{"cell_type":"code","source":["def prob(dataset, max_bins=10):\n    \"\"\"Joint probability distribution P(X) for the given data.\"\"\"\n\n    # bin by the number of different values per feature\n    num_rows, num_columns = dataset.shape\n    bins = [min(len(np.unique(dataset[:, ci])), max_bins) for ci in range(num_columns)]\n\n    freq, _ = np.histogramdd(dataset, bins)\n    p = freq / np.sum(freq)\n    return p\n\ndef shannon_entropy(p):\n    \"\"\"Shannon entropy H(X) is the sum of P(X)log(P(X)) for probabilty distribution P(X).\"\"\"\n    p = p.flatten()\n    return -sum(pi*np.log2(pi) for pi in p if pi)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f511a19-7299-479d-bce4-62196e815462"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Conditional Shannon Entropy\n\nConditional SE (CSE) measures the information in one signal, $X$, when the value of another signal, $Y$, is known: \n\n$\\begin{aligned} H(X|Y) \n& = H(X,Y)-H(Y) \\\\\n& = - \\sum_{x \\in X} p(x, y) \\log p(x, y) - H(Y) \\end{aligned}$\n\nwhere joint SE, $H(X,Y)$, measures the information in both signals together, with $p(x,y)$ being their joint probability. For example, knowing that it's winter reduces the information value of news that it is raining."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfa03b6d-ff4c-4921-8a07-5a277ae680c3"}}},{"cell_type":"code","source":["def conditional_shannon_entropy(p, *conditional_indices):\n    \"\"\"Shannon entropy of P(X) conditional on variable j\"\"\"\n\n    axis = tuple(i for i in np.arange(len(p.shape)) if i not in conditional_indices)\n\n    return shannon_entropy(p) - shannon_entropy(np.sum(p, axis=axis))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5c885b6-71ab-4056-9116-d3a7b2c6796d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Mutual Information\n[Mutual information](https://en.wikipedia.org/wiki/Mutual_information) between variables $X$ and $Y$ is defined as \n\n$I(X;Y)  = \\sum_{y \\in Y} \\sum_{x \\in X} p(x, y) \\log \\frac{p(x,y)}{p(x)p(y)}$\n\nwhere $p(x)$ and $p(y)$ are marginal probabilities of $X$ and $Y$, and $p(x,y)$ the joint probability. Equivalently, \n\n$I(X;Y)  = H(Y) - H(Y|X)$\n\nwhere $H(Y)$ is the SE of $Y$ and $H(Y|X)$ is the CSE of $Y$ conditional on $X$.\n\nMutual information (MI) quantifies how much one knows about one random variable from observations of another. Intuitively, a model based on just one of a pair of features (e.g., farmer MacDonald's water rations and soil humidity) will better reproduce their combined contribution when MI between them is high."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7cdfb006-a897-4052-b6d7-e67d17d55ea3"}}},{"cell_type":"code","source":["def mutual_information(p, j):\n    \"\"\"Mutual information between all variables and variable j\"\"\"\n    return shannon_entropy(np.sum(p, axis=j)) - conditional_shannon_entropy(p, j)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2632dec5-4898-4933-8ac8-a3599fc9679d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Conditional Mutual Information\n\nConditional mutual information (CMI) between a variable of interest, $X$, and a feature, $Y$, given the selection of another feature, $Z$, is given by\n\n$I(X;Y|Z) = H(X|Z)-H(X|Y,Z)$\n\nwhere $H(X|Z)$ is the CSE of $X$ conditional on $Z$ and $H(X|Y, Z)$ is the CSE of $X$ conditional on both $Y$ and $Z$.\n\nIn this code cell, because marginalization over $j$ removes a dimension, any conditional indices pointing to subsequent dimensions are decremented by 1."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b91b042-6d55-48b3-8405-e44978c0bb26"}}},{"cell_type":"code","source":["def conditional_mutual_information(p, j, *conditional_indices):\n    \"\"\"Mutual information between variables X and variable Y conditional on variable Z.\"\"\"\n\n    marginal_conditional_indices = [i-1 if i > j else i for i in conditional_indices]\n\n    return (conditional_shannon_entropy(np.sum(p, axis=j), *marginal_conditional_indices)\n            - conditional_shannon_entropy(p, j, *conditional_indices))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04e30d14-eac4-48ad-af3b-52b128d67e0c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"0 - Library","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4018072087305158}},"nbformat":4,"nbformat_minor":0}
